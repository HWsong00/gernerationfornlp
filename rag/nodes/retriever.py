"""
Retriever Node: ì „ëµ ë¶„ë¥˜, ì¿¼ë¦¬ ìƒì„±, Dual Search ìˆ˜í–‰
"""
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from .state import MCQState
from utils.llm import llm_with_params

def retrieve_node(state: MCQState):
    """
    í•œêµ­ì‚¬ ë¬¸ì œì— ëŒ€í•´ ì „ëµì„ ë¶„ë¥˜í•˜ê³ , í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ë©°, Dual Searchë¥¼ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ
    
    Args:
        state: MCQState
        
    Returns:
        dict: {
            "strategy": str,
            "summary": str,
            "optimized_query": str,
            "retrieved_context": str
        }
    """
    if not state.get('is_history'):
        return {"retrieved_context": "í•œêµ­ì‚¬ ë¬¸ì œê°€ ì•„ë‹ˆë¯€ë¡œ ê²€ìƒ‰ì„ ìƒëµí•©ë‹ˆë‹¤."}

    # Phase 1: INFERENCE vs GENERAL ë¶„ë¥˜
    router_prompt = ChatPromptTemplate.from_template(
        "<|im_start|>system\në¬¸ì œë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”: \n"
        "- **INFERENCE**: (ê°€), 'ì´ ì™•', 'ì´ ë‹¨ì²´' ë“± ì£¼ì–´ê°€ ìƒëµë˜ì–´ ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš°\n"
        "- **GENERAL**: ëŒ€ìƒì´ ëª…í™•í•œ ì‚¬ì‹¤ í™•ì¸ ë¬¸ì œ\n"
        "ë‹¨ì–´ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.<|im_end|>\n"
        "<|im_start|>user\nì§€ë¬¸: {paragraph}\nì§ˆë¬¸: {question}\në¶„ë¥˜:<|im_end|>\n<|im_start|>assistant\n"
    )
    
    # Note: llm_with_paramsëŠ” ì™¸ë¶€ì—ì„œ ì •ì˜ë˜ì–´ì•¼ í•¨
    strategy = (router_prompt | llm_with_params | StrOutputParser()).invoke(state).strip()

    # Phase 2: ìš”ì•½ ë° 10ëŒ€ í‚¤ì›Œë“œ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ ê¶Œì¥ì´ë‚˜ ì—¬ê¸°ì„  ìˆœì°¨ êµ¬í˜„)
    gen_prompt = ChatPromptTemplate.from_template(
        "<|im_start|>system\në‹¹ì‹ ì€ ì—­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:\n"
        "1. ì§€ë¬¸ì„ 2ë¬¸ì¥ ì´ë‚´ë¡œ í•µì‹¬ ìš”ì•½í•˜ì„¸ìš”.\n"
        "2. ê²€ìƒ‰ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 'ì½¤ë§ˆ'ë¡œ êµ¬ë¶„í•˜ì—¬ 10ê°œ ì´ë‚´ë¡œ ë½‘ìœ¼ì„¸ìš”.\n"
        "í˜•ì‹: ìš”ì•½: [ë‚´ìš©] / í‚¤ì›Œë“œ: [í‚¤ì›Œë“œë“¤]<|im_end|>\n"
        "<|im_start|>user\nì§€ë¬¸: {paragraph}\nì§ˆë¬¸: {question}\nê²°ê³¼:<|im_end|>\n<|im_start|>assistant\n"
    )
    gen_res = (gen_prompt | llm_with_params | StrOutputParser()).invoke(state)

    summary = gen_res.split("ìš”ì•½:")[1].split("/ í‚¤ì›Œë“œ:")[0].strip()
    keywords = gen_res.split("í‚¤ì›Œë“œ:")[1].strip()

    print(f"   ğŸš¦ [ì „ëµ]: {strategy} | âœ¨ [í‚¤ì›Œë“œ]: {keywords}")

    # Phase 3: Dual Search (í‚¤ì›Œë“œ ì¿¼ë¦¬ + ì§€ë¬¸ ìš”ì•½)
    # Note: hybrid_retrieverëŠ” ì™¸ë¶€ì—ì„œ ì •ì˜ë˜ì–´ì•¼ í•¨
    docs_query = hybrid_retriever.invoke(keywords)
    docs_summary = hybrid_retriever.invoke(summary)

    # ì¤‘ë³µ ì œê±° ë° ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
    combined = {d.page_content: d for d in (docs_query + docs_summary)}.values()
    para_context = "\n".join([f"- {d.page_content}" for d in list(combined)[:6]])

    return {
        "strategy": strategy,
        "summary": summary,
        "optimized_query": keywords,
        "retrieved_context": f"ì „ëµ: {strategy}\nìš”ì•½: {summary}\nì°¸ê³ ìë£Œ:\n{para_context}"
    }