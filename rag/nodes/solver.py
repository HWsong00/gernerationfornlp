import re
import json
from nodes.state import MCQState
from utils.llm import get_llm_client, MODEL_NAME

# =========================================================
# 1. í•œêµ­ì‚¬ ì „ìš© Solver Node (Native SDK + RAG)
# =========================================================
def ko_history_solver_node(state: MCQState):
    """
    í•œêµ­ì‚¬ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Native SDKë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.
    (ë­ì²´ì¸ ê±·ì–´ë‚´ê¸°: í…œí”Œë¦¿ ëŒ€ì‹  Raw ë©”ì‹œì§€ ì‚¬ìš©)
    """
    client = get_llm_client()
    
    # ì„ ì§€ í¬ë§·íŒ…
    choices_str = "\n".join([f"{i+1}. {c}" for i, c in enumerate(state['choices'])])
    
    # íŒ€ì›ì˜ ì„±ê³µ ë¹„ê²°: ê°•ë ¥í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì œì•½ ì¡°ê±´
    system_msg = """ë‹¹ì‹ ì€ ì‚¬ë£Œ í•´ì„ì— ëŠ¥ìˆ™í•œ í•œêµ­ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ <ê°œë… ë³´ì¶© ìë£Œ>ì˜ ê° ë¬¸ì„œ([1], [2] ë“±)ë¥¼ ê·¼ê±°ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
1. ë‹µë³€ ì „ <think> íƒœê·¸ ë‚´ì—ì„œ ë‹¨ê³„ë³„ë¡œ ì¶”ë¡ í•˜ë˜, í–ˆë˜ ë§ì„ ì ˆëŒ€ ë°˜ë³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. 7ë‹¨ê³„ ë‚´ì— ê²°ë¡ ì´ ë‚˜ì§€ ì•Šìœ¼ë©´ ì¦‰ì‹œ ì¶”ë¡ ì„ ë©ˆì¶”ê³  ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ë‹µì„ ì„ íƒí•˜ì‹­ì‹œì˜¤.
3. ì •ë‹µì€ ë°˜ë“œì‹œ ì„ íƒì§€ ë²ˆí˜¸ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•˜ë©°, ë§ˆì§€ë§‰ì— JSON í˜•ì‹ {"ì •ë‹µ": "ë²ˆí˜¸"}ë¡œ ë‹µë³€ì„ ì¢…ë£Œí•˜ì‹­ì‹œì˜¤."""

    user_msg = f"""<ì§€ë¬¸>
{state['paragraph']}

<ê°œë… ë³´ì¶© ìë£Œ>
{state.get('retrieved_context', "ê´€ë ¨ ìë£Œ ì—†ìŒ")}

<ì§ˆë¬¸>
{state['question']}

<ì„ ì§€>
{choices_str}"""

    print(f"ğŸ¤– [History Solver] Native ì¶”ë¡  ì‹œì‘ (ID: {state['id']})")
    
    # Native í˜¸ì¶œ: repetition_penalty ì£¼ì…ìœ¼ë¡œ ë£¨í”„ ë¬¼ë¦¬ì  ì°¨ë‹¨
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg}
        ],
        temperature=0.7,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± ìœ ì§€
        max_tokens=8192,
        extra_body={
            "repetition_penalty": 1.15, # ë£¨í”„ë¥¼ ë°©ì§€í•˜ëŠ” ê°€ì¥ ê°•ë ¥í•œ ì¥ì¹˜
        },
        stop=["<|im_end|>", "###"] # ë‹µë³€ì´ ëŠ˜ì–´ì§€ëŠ” ê²ƒì„ ë°©ì§€
    )
    
    return {"full_response": response.choices[0].message.content}


# =========================================================
# 2. ì¼ë°˜ ê³¼ëª© Solver Node (Native SDK)
# =========================================================
def general_solver_node(state: MCQState):
    """
    ì¼ë°˜ ê³¼ëª©ì„ ìœ„í•œ Native SDK ë…¸ë“œì…ë‹ˆë‹¤.
    """
    client = get_llm_client()
    
    choices_str = "\n".join([f"{i+1}. {c}" for i, c in enumerate(state['choices'])])
    
    system_msg = """ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ê°ê´€ì ì¸ ìˆ˜í—˜ìƒì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§€ë¬¸ë§Œì„ ë¶„ì„í•˜ì—¬ ì •ë‹µì„ ê³ ë¥´ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
1. <think> íƒœê·¸ ë‚´ì—ì„œ ìµœëŒ€ 7ë‹¨ê³„ì˜ ë…¼ë¦¬ ì „ê°œë¥¼ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤. ë˜‘ê°™ì€ ë¬¸ì¥ì„ ë°˜ë³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. ì •ë³´ê°€ ë¶€ì¡±í•˜ë”ë¼ë„ ê°€ì¥ íƒ€ë‹¹í•´ ë³´ì´ëŠ” ë²ˆí˜¸ë¥¼ ê³ ë¥´ì‹­ì‹œì˜¤.
3. ë§ˆì§€ë§‰ ì¤„ì€ ë°˜ë“œì‹œ {"ì •ë‹µ": "ë²ˆí˜¸"} í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."""

    user_msg = f"[ì§€ë¬¸]: {state['paragraph']}\n[ì§ˆë¬¸]: {state['question']}\n[ì„ ì§€]:\n{choices_str}"

    print(f"ğŸ¤– [General Solver] Native ì¶”ë¡  ì‹œì‘ (ID: {state['id']})")

    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg}
        ],
        temperature=0.7,
        max_tokens=8192,
        extra_body={
            "repetition_penalty": 1.15
        }
    )

    return {'full_response': response.choices[0].message.content}


# =========================================================
# 3. Recovery Node (Native SDK ê¸°ë°˜ ë¹„ìƒ ì¶”ì¶œ)
# =========================================================
def recovery_node(state: MCQState):
    """
    Native SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ë¡œê·¸ì—ì„œ ì •ë‹µ ë²ˆí˜¸ë¥¼ ê°•ì œë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    client = get_llm_client()
    
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì±„ì ê´€ì…ë‹ˆë‹¤. ì•„ë˜ ì¶”ë¡  ë‚´ìš©ì—ì„œ ìµœì¢… ì •ë‹µ ë²ˆí˜¸ í•˜ë‚˜ë§Œ ìˆ«ìë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”."},
        {"role": "human", "content": f"ì´ì „ ì¶”ë¡  ë‚´ìš©: {state['full_response']}\n\nê²°êµ­ ì •ë‹µì€ ëª‡ ë²ˆì…ë‹ˆê¹Œ?"}
    ]
    
    print(f"ğŸš¨ [Recovery] Native ë¹„ìƒ ì •ë‹µ ì¶”ì¶œ (ID: {state['id']})")
    
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        temperature=0,
        max_tokens=10 # ìˆ«ìë§Œ í•„ìš”í•˜ë¯€ë¡œ ìµœì†Œí™”
    )
    
    content = response.choices[0].message.content
    match = re.search(r"\d", content)
    final_answer = match.group(0) if match else "1" 
    
    return {"final_answer": final_answer}