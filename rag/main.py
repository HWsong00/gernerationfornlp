import os
import json
import pandas as pd
from tqdm import tqdm
from dotenv import load_dotenv

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from utils.llm import get_llm
from utils.langfuse import langfuse_handler
from graph.workflow import create_mcq_workflow
from nodes.state import MCQState

# (ì£¼ì˜) ì´ì „ ëŒ€í™”ì—ì„œ ì •ì˜í•œ ensemble_retriever ê°ì²´ì™€ ë²¡í„° ë°ì´í„° ë¡œë“œ í•„ìš”
# ì—¬ê¸°ì„œëŠ” ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜ ì´ˆê¸°í™” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
# from utils.retrieval_setup import init_ensemble_retriever 

def load_dataset(path):
    """869ê°œì˜ ë¬¸ì œê°€ ë‹´ê¸´ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def main(is_test=False):
    load_dotenv()
    
    # 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
    DATA_PATH = os.getenv("DATA_PATH", "./data/history_test_set.json")
    OUTPUT_PATH = "./results/final_results.csv"
    os.makedirs("./results", exist_ok=True)
    
    dataset = load_dataset(DATA_PATH)
    if is_test:
        dataset = dataset[:3]  # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¼ ë•ŒëŠ” 3ê°œë§Œ ì‹¤í–‰
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ (ìƒ˜í”Œ {len(dataset)}ê°œ)")

    # 2. ì¸í”„ë¼ ì´ˆê¸°í™” (Ensemble Retriever & Workflow)
    # ensemble_retrieverëŠ” ì¥(Jang)ë‹˜ì´ êµ¬ì„±í•˜ì‹  BM25 + Chroma ê°ì²´ì…ë‹ˆë‹¤.
    # precomputed_vectorsë„ ì—¬ê¸°ì„œ ë¡œë“œí•˜ì—¬ ìƒíƒœì— ì£¼ì…í•©ë‹ˆë‹¤.
    print("ğŸš€ ì¸í”„ë¼ ì´ˆê¸°í™” ì¤‘ (30B ëª¨ë¸ ë¡œë“œ í¬í•¨)...")
    app = create_mcq_workflow(ensemble_retriever=None) # ì—¬ê¸°ì— ì‹¤ì œ ê°ì²´ ì£¼ì…
    
    results = []
    checkpoint_interval = 10 # 10ë¬¸ì œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥

    # 3. ë©”ì¸ ë£¨í”„ (tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ)
    print(f"ğŸƒ ì „ì²´ {len(dataset)}ë¬¸í•­ í’€ì´ ì‹œì‘!")
    
    for i, item in enumerate(tqdm(dataset)):
        problem_id = item.get('id', str(i))
        
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        initial_state = {
            "id": problem_id,
            "paragraph": item['paragraph'],
            "question": item['question'],
            "choices": item['choices'],
            "precomputed_vectors": {}, # ì‚¬ì „ ê³„ì‚°ëœ ë²¡í„° ì£¼ì…
            "is_korean_history": False,
            "final_answer": "N/A"
        }

        try:
            # 4. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Langfuse í•¸ë“¤ëŸ¬ í¬í•¨)
            config = {"callbacks": [langfuse_handler]} if langfuse_handler else {}
            final_state = app.invoke(initial_state, config=config)
            
            # ê²°ê³¼ ì €ì¥
            results.append({
                "id": problem_id,
                "answer": final_state.get("final_answer"),
                "full_log": final_state.get("full_response")
            })

        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ (ID: {problem_id}): {e}")
            results.append({"id": problem_id, "answer": "ERROR", "full_log": str(e)})

        # 5. ì¤‘ê°„ ì €ì¥ (Checkpoint)
        if (i + 1) % checkpoint_interval == 0:
            pd.DataFrame(results).to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')
            # print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ ({i+1}/{len(dataset)})")

    # 6. ìµœì¢… ì €ì¥
    final_df = pd.DataFrame(results)
    final_df.to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')
    print(f"ğŸ‰ ëª¨ë“  í’€ì´ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {OUTPUT_PATH}")

if __name__ == "__main__":
    # ì‹¤í–‰ ì „ í…ŒìŠ¤íŠ¸: main(is_test=True)
    # ë³¸ ê²Œì„ ì‹¤í–‰: main(is_test=False)
    main(is_test=True)