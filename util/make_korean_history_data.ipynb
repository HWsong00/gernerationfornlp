{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gPk9a6Qs2gh",
        "outputId": "a81dfcfc-ea4f-481f-9e96-83d0c67c623e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì„±ê³µì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!\n",
            "--------------------------------------------------\n",
            "ì´ì„¤ ï¼í•œêµ­ì‚¬ì˜ ì „ê°œï¼\n",
            "â… . í•œêµ­ì‚¬ì˜ ì „ê°œë¥¼ ë³´ëŠ” ì‹œê°\n",
            "í•œêµ­ì‚¬ëŠ” ì–´ë–»ê²Œ ì „ê°œë˜ì–´ ì™”ì„ê¹Œ. ì´ì— ëŒ€í•´ì„œëŠ” ì˜¤ë˜ ì „ë¶€í„° ç‹æœì˜ í¥ë§ì„ ê¸°ì¤€ìœ¼ë¡œ ë³´ëŠ” ê²¬í•´ê°€ í–‰í•´ì ¸ ì™”ë‹¤. í•œ ì™•ì¡°ê°€ ë§í•˜ê³  ë‹¤ë¥¸ í•œ ì™•ì¡°ê°€ ì¼ì–´ë‚˜ëŠ” ë°ì—ëŠ” ê·¸ëŸ´ë§Œí•œ ì´ìœ ê°€ ìˆëŠ” ê²ƒì´ë¯€ë¡œ, ì´ ê°™ì€ ì†Œìœ„ ç‹æœå²è§€ì€ ê·¸ê²ƒëŒ€ë¡œ ì˜ë¯¸ê°€ ìˆëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ í•œí¸ ìƒê°í•˜ë©´, ì™•ì¡°ì˜ êµì²´ì—ë„ ë¶ˆêµ¬í•˜ê³  ì‚¬íšŒì ì¸ ë™ì§ˆì„±ì´ ìœ ì§€ë˜ëŠ” ê²½ìš°ë„ ìˆê³ , ë˜ ê°™ì€ ì™•ì¡° ì•ˆì—ì„œë„ ì‚¬íšŒì ì¸ ë³€í™”ê°€ ë°œê²¬ë˜ëŠ” ê²½ìš°ë„ ìˆë‹¤. ì™•ì¡°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—­ì‚¬ì˜ ì „ê°œë¥¼ ì´í•´í•˜ëŠ” ë°ì— ë§Œì¡±í•  ìˆ˜ê°€ ì—†ëŠ” ê¹Œë‹­ì´ ì´ëŸ¬í•œ ë°ì— ìˆëŠ” ê²ƒì´ë‹¤.\n",
            "ì™•ì¡° ì¤‘ì‹¬ì˜ ì—­ì‚¬ê´€ì„ ê·¹ë³µí•˜ê¸° ìœ„í•˜ì—¬ ì œê¸°ëœ ìƒˆë¡œìš´ ë°©ë²•ì´ í•œêµ­ì‚¬ì˜ ì „ê°œê³¼ì •ì„ å¤ä»£Â·ä¸­ä¸–Â·è¿‘ä»£ì˜ ì„¸ ì‹œê¸°ë¡œ ë‚˜ëˆ„ì–´ì„œ ì´í•´í•˜ëŠ” ê²ƒì´ì—ˆë‹¤. ê·¸ëŸ°ë° ì´ ê°™ì€ ì˜ˆë“¤ì„ ì‚´í´ë³´ë©´, ë¹„ë¡ ìš©ì–´ëŠ” ë‹¬ë¼ì¡Œì§€ë§Œ ì‹¤ì œì— ìˆì–´ì„œëŠ” ì™•ì¡° ì¤‘ì‹¬ì˜ ê´€ì ê³¼ ë³„ë¡œ ë‹¤ë¥¼ ë°”ê°€ ì—†ëŠ” ê²ƒì´ë‹¤. ê·¸ë˜ì„œ ì¤‘ì„¸ì™€ ê·¼ëŒ€ ì‚¬ì´ì— è¿‘ä¸–ë¼ëŠ” ì‹œëŒ€ë¥¼ ì„¤ì •í•˜ì—¬ é«˜éº—ç‹æœì™€ êµ¬ë³„í•˜ë©° æœé®®ç‹æœë¥¼ \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# 1. ì˜®ê²¨ê°„ ìƒˆ ì‚¬ì´íŠ¸ ì£¼ì†Œ\n",
        "url = \"https://contents.history.go.kr/front/nh/view.do\"\n",
        "\n",
        "# 2. ê¸ê³  ì‹¶ì€ ID (íŒŒë¼ë¯¸í„°)\n",
        "params = {\n",
        "    \"levelId\": \"nh_001_0010\"\n",
        "}\n",
        "\n",
        "# 3. ì‚¬ëŒì¸ ì²™ í•˜ê¸° (í—¤ë” í•„ìˆ˜!)\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    # ìš”ì²­ ë°œì‚¬!\n",
        "    response = requests.get(url, params=params, headers=headers)\n",
        "    response.raise_for_status() # ì—ëŸ¬ ë‚˜ë©´ ë©ˆì¶¤\n",
        "\n",
        "    # HTML íŒŒì‹±\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # --- [ì¤‘ìš”] ë³¸ë¬¸ ì°¾ëŠ” ë¶€ë¶„ ---\n",
        "    # ê°œë°œì ë„êµ¬ë¡œ ë³¸ë¬¸ ê°ì‹¸ê³  ìˆëŠ” íƒœê·¸ì˜ class ì´ë¦„ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    # ë³´í†µ ê³µê³µê¸°ê´€ ì‚¬ì´íŠ¸ëŠ” 'view_cont', 'con_view', 'txt-wrap' ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
        "    # ì¼ë‹¨ ê°€ì¥ ìœ ë ¥í•œ í›„ë³´ë“¤ë¡œ ì°¾ì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "    content_div = soup.find('div', class_='article') # í›„ë³´ 1\n",
        "    if not content_div:\n",
        "        content_div = soup.find('div', class_='txt-wrap') # í›„ë³´ 2\n",
        "\n",
        "    if content_div:\n",
        "        # ê°ì£¼(íŒì—…) ì œê±° ë¡œì§ (ì´ì „ê³¼ ë™ì¼)\n",
        "        for footnote in content_div.find_all('span', class_='popup-type1'):\n",
        "            footnote.decompose()\n",
        "        for footnote in content_div.find_all('a', class_='note_link'): # í˜¹ì‹œ íƒœê·¸ê°€ aë¼ë©´\n",
        "            footnote.decompose()\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "        final_text = content_div.get_text(separator=\"\\n\", strip=True)\n",
        "        print(\"âœ… ì„±ê³µì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!\")\n",
        "        print(\"-\" * 50)\n",
        "        print(final_text[:500]) # ì•ë¶€ë¶„ 500ì ì¶œë ¥\n",
        "    else:\n",
        "        print(\"âŒ ë³¸ë¬¸ íƒœê·¸(div)ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ê°œë°œì ë„êµ¬(F12) -> Elements íƒ­ì—ì„œ ë³¸ë¬¸ì´ ì–´ë–¤ class ì´ë¦„ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ì—ëŸ¬ ë°œìƒ: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# ==========================================\n",
        "# 1.ì„¸ì…˜ ì„¤ì • (ì„œë²„ê°€ ëŠì–´ë„ 5ë²ˆ ë‹¤ì‹œ ë¶™ìŒ)\n",
        "# ==========================================\n",
        "session = requests.Session()\n",
        "# ì ‘ì† ëŠê¹€(ConnectionError), 5xx ì—ëŸ¬ ì‹œ 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ìµœëŒ€ 5ë²ˆ ì¬ì‹œë„\n",
        "retries = Retry(total=5, backoff_factor=0.5, status_forcelist=[500, 502, 503, 504])\n",
        "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# ë°ì´í„° ì €ì¥í•  í´ë”\n",
        "if not os.path.exists(\"history_data_final\"):\n",
        "    os.makedirs(\"history_data_final\")\n",
        "\n",
        "base_url = \"https://contents.history.go.kr/front/nh/view.do\"\n",
        "\n",
        "print(\" 1ê¶Œ~52ê¶Œ ì „ìˆ˜ ì¡°ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. ì „ê¶Œ ë£¨í”„ (1 ~ 52)\n",
        "# ==========================================\n",
        "for vol in range(1, 53):\n",
        "    vol_str = f\"{vol:03d}\"\n",
        "    root_id = f\"nh_{vol_str}\"\n",
        "\n",
        "    print(f\"ğŸ“˜ [{root_id}] ì‘ì—… ì‹œì‘...\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # (A) ì§€ë„(ID ë¦¬ìŠ¤íŠ¸) í™•ë³´\n",
        "    # -------------------------------------------------\n",
        "    # ì§„ì…ì : ê° ê¶Œì˜ ë©”ì¸ í˜ì´ì§€ (ì—¬ê¸°ì— ì „ì²´ í•˜ìœ„ IDê°€ ìˆ¨ì–´ìˆìŒ)\n",
        "    try:\n",
        "        # timeoutì„ ë„‰ë„‰íˆ 20ì´ˆ ì¤Œ\n",
        "        response = session.get(base_url, params={\"levelId\": root_id}, headers=headers, timeout=20)\n",
        "        html_source = response.text\n",
        "\n",
        "        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ nh_00X_... íŒ¨í„´ ì‹¹ ê¸ê¸°\n",
        "        pattern = f\"({root_id}_[0-9_]+)\"\n",
        "        found_ids = re.findall(pattern, html_source)\n",
        "        all_ids = sorted(list(set(found_ids)))\n",
        "\n",
        "        # ìê¸° ìì‹ (root_id)ì€ ì œì™¸ (ëª©ì°¨ í˜ì´ì§€ì¼ í™•ë¥  ë†’ìŒ)\n",
        "        if root_id in all_ids: all_ids.remove(root_id)\n",
        "\n",
        "        print(f\"   -> ì§€ë„ í™•ë³´ ì™„ë£Œ! ({len(all_ids)}ê°œ ì±•í„°)\")\n",
        "\n",
        "        if len(all_ids) == 0:\n",
        "            print(\"   âš ï¸ IDë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì§€ë„ í™•ë³´ ì¤‘ ì¹˜ëª…ì  ì—ëŸ¬: {e}\")\n",
        "        continue\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # (B) ë³¸ë¬¸ í¬ë¡¤ë§\n",
        "    # -------------------------------------------------\n",
        "    dataset = []\n",
        "\n",
        "    # ì§„í–‰ë°” í‘œì‹œ\n",
        "    for target_id in tqdm(all_ids, desc=f\"{vol_str}ê¶Œ ìˆ˜ì§‘\"):\n",
        "        try:\n",
        "            # timeout=10ì´ˆ. 10ì´ˆ ë™ì•ˆ ë‹µ ì—†ìœ¼ë©´ ì¬ì‹œë„ í•˜ê±°ë‚˜ ë„˜ì–´ê°\n",
        "            res = session.get(base_url, params={\"levelId\": target_id}, headers=headers, timeout=10)\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "            # ë‹˜ê»˜ì„œ í™•ì¸í•˜ì‹  ê·¸ 'article' í´ë˜ìŠ¤!\n",
        "            article_div = soup.find('div', class_='article')\n",
        "\n",
        "            if article_div:\n",
        "                # ì œëª© ì¶”ì¶œ\n",
        "                title_tag = soup.find('h3', class_='view_tit')\n",
        "                if not title_tag:\n",
        "                    title_tag = soup.find('h4', class_='tit') # í˜¹ì‹œ ëª°ë¼ ì˜ˆë¹„ìš©\n",
        "\n",
        "                title = title_tag.get_text(strip=True) if title_tag else \"ì œëª© ì—†ìŒ\"\n",
        "\n",
        "                # ë¶ˆí•„ìš”í•œ íƒœê·¸(ê°ì£¼, ë§í¬) ì‚­ì œ\n",
        "                for tag in article_div.find_all(['sup', 'a']):\n",
        "                    tag.decompose()\n",
        "\n",
        "                # ë³¸ë¬¸ í…ìŠ¤íŠ¸\n",
        "                content = article_div.get_text(separator=\"\\n\\n\", strip=True)\n",
        "\n",
        "                # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(ë¹ˆ í˜ì´ì§€) ì €ì¥ ì•ˆ í•¨\n",
        "                if len(content) > 30:\n",
        "                    dataset.append({\n",
        "                        \"id\": target_id,\n",
        "                        \"title\": title,\n",
        "                        \"text\": content,\n",
        "                        \"volume\": vol,\n",
        "                        \"source\": res.url\n",
        "                    })\n",
        "\n",
        "            # ì„œë²„ì— ë„ˆë¬´ ë¬´ë¦¬ ì£¼ì§€ ì•Šê²Œ 0.05ì´ˆ íœ´ì‹\n",
        "            time.sleep(0.05)\n",
        "\n",
        "        except Exception as e:\n",
        "            # í•˜ë‚˜ ì‹¤íŒ¨í•´ë„ ì¿¨í•˜ê²Œ ë„˜ì–´ê° (ì „ì²´ ì¤‘ë‹¨ X)\n",
        "            # print(f\"ì—ëŸ¬({target_id}): {e}\")\n",
        "            pass\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # (C) íŒŒì¼ ì €ì¥\n",
        "    # -------------------------------------------------\n",
        "    if dataset:\n",
        "        filename = f\"history_data_final/nh_{vol_str}.json\"\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"   ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename} (ì´ {len(dataset)}ê±´)\\n\")\n",
        "    else:\n",
        "        print(f\"   ğŸ’¨ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\\n\")\n",
        "\n",
        "print(\"ğŸ‰ ëŒ€ì¥ì • ì™„ë£Œ! ê³ ìƒí•˜ì…¨ìŠµë‹ˆë‹¤!\")"
      ],
      "metadata": {
        "id": "xpNThYHJPSlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# 1. ì••ì¶•í•  í´ë” ì´ë¦„ (ì•„ê¹Œ ì½”ë“œì—ì„œ ì„¤ì •í•œ ì´ë¦„)\n",
        "target_folder = \"history_data_final\"\n",
        "output_filename = \"korean_history_full_52vol\"\n",
        "\n",
        "# í´ë”ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸\n",
        "if os.path.exists(target_folder):\n",
        "    print(f\"ğŸ“¦ '{target_folder}' í´ë”ë¥¼ '{output_filename}.zip'ìœ¼ë¡œ ì••ì¶• ì¤‘...\")\n",
        "\n",
        "    # 2. zip íŒŒì¼ë¡œ ì••ì¶• (shutil ì‚¬ìš©)\n",
        "    shutil.make_archive(output_filename, 'zip', target_folder)\n",
        "\n",
        "    print(f\"âœ… ì••ì¶• ì™„ë£Œ! ({output_filename}.zip)\")\n",
        "    print(\"â¬‡ï¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "    # 3. ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "    files.download(f\"{output_filename}.zip\")\n",
        "\n",
        "else:\n",
        "    print(f\"âŒ '{target_folder}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "rok9PULlSXxl",
        "outputId": "83fef8ca-01af-4951-c3a5-dccdc666ff8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ 'history_data_final' í´ë”ë¥¼ 'korean_history_full_52vol.zip'ìœ¼ë¡œ ì••ì¶• ì¤‘...\n",
            "âœ… ì••ì¶• ì™„ë£Œ! (korean_history_full_52vol.zip)\n",
            "â¬‡ï¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9254b36b-3a73-4971-a246-9642ec15b096\", \"korean_history_full_52vol.zip\", 19822836)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2HDuiHUnvRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}