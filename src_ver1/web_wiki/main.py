import os
import gc
import torch
import time
import ast
import pandas as pd
from tqdm.auto import tqdm
from functools import partial

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from config import settings
from data_load.loader import load_and_split_data
from retrievers.dense_retriever import DenseResourceManager, build_dense_retriever
from retrievers.sparse_retriever import LangChainKiwiBM25Retriever
from retrievers.ensemble import CustomWeightedEnsembleRetriever
from retrievers.tokenizer import tokenize_kiwi
from utils.llm import start_llama_server, get_llm_client  # ì„œë²„ ì‹œì‘ ë° í´ë¼ì´ì–¸íŠ¸ ë¡œì§ í¬í•¨
from utils.reranker import get_reranker
from utils.langfuse import langfuse_handler
from graph.workflow import create_mcq_workflow

def initialize_resources():
    """ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ë° ì„œë²„ ê°€ë™ í™•ì¸"""
    # 1. ì„œë²„ ê°€ë™ ë° ëŒ€ê¸° (20ë¶„ íƒ€ì„ì•„ì›ƒ ì ìš©ëœ ë²„ì „ í˜¸ì¶œ)
    print("ğŸŒ [0/3] LLM ì„œë²„ ìƒíƒœ í™•ì¸ ë° ê°€ë™ ì¤‘...")
    start_llama_server() 
    
    print("âš™ï¸ [1/3] ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ë° ë¬¸ì„œ ì¸ë±ì‹± ì¤‘...")
    documents = load_and_split_data(settings.DATA_PATH)
    
    # Dense ë¦¬íŠ¸ë¦¬ë²„ (BGE-M3)
    dense_manager = DenseResourceManager(model_name="dragonkue/BGE-m3-ko")
    vectorstore = build_dense_retriever(documents, dense_manager)
    
    # Sparse ë¦¬íŠ¸ë¦¬ë²„ (Kiwi-BM25)
    corpus_tokenizer = partial(tokenize_kiwi, text_type="corpus")
    query_tokenizer = partial(tokenize_kiwi, text_type="query")
    sparse_retriever = LangChainKiwiBM25Retriever(
        documents=documents, k=10,
        corpus_tokenizer=corpus_tokenizer,
        query_tokenizer=query_tokenizer
    )
    
    # ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ì¡°ë¦½
    ensemble_retriever = CustomWeightedEnsembleRetriever(
        sparse_retriever=sparse_retriever,
        vectorstore=vectorstore,
        weights=[0.3, 0.7], top_k=3
    )
    
    print("âš™ï¸ [2/3] ë¦¬ë­ì»¤ ëª¨ë¸ ë¡œë“œ ë° ì›Œí¬í”Œë¡œìš° ì¡°ë¦½ ì¤‘...")
    reranker_instance = get_reranker()
    # ëŒë‹¤ ì£¼ì… ë°©ì‹ìœ¼ë¡œ ë„êµ¬ì™€ ìƒíƒœ ë¶„ë¦¬
    app = create_mcq_workflow(ensemble_retriever, reranker_instance)
    
    print("âœ… [3/3] ëª¨ë“  ë¦¬ì†ŒìŠ¤ ë° ì„œë²„ ì¤€ë¹„ ì™„ë£Œ")
    return app

def main():
    # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„œë²„ ê°€ë™ í¬í•¨)
    try:
        app = initialize_resources()
    except Exception as e:
        print(f"ğŸš¨ ì´ˆê¸°í™” ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    # 2. ë°ì´í„° ë¡œë“œ (ê²½ë¡œëŠ” ë³¸ì¸ í™˜ê²½ì— ë§ì¶° ìˆ˜ì •)
    csv_path = "data/test.csv"
    if not os.path.exists(csv_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return
        
    train_df = pd.read_csv(csv_path)
    results = []
    
    print(f"ğŸš€ ì´ {len(train_df)}ë¬¸ì œ ë°°ì¹˜ í’€ì´ ì‹œì‘ (Target: A100 80GB)")

    # 3. ë°°ì¹˜ ë£¨í”„
    for index, row in tqdm(train_df.iterrows(), total=len(train_df)):
        try:
            # ë¬¸ì œ ë°ì´í„° íŒŒì‹±
            prob_data = row['problems']
            if isinstance(prob_data, str):
                prob_data = ast.literal_eval(prob_data)
            if isinstance(prob_data, list):
                prob_data = prob_data[0]

            # ë­ê·¸ë˜í”„ State ì…ë ¥ ë°ì´í„° (ê°ì²´ëŠ” ì œì™¸í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œ!)
            sample_input = {
                "id": str(row['id']),
                "paragraph": row['paragraph'],
                "question": prob_data.get('question', ''),
                "choices": prob_data.get('choices', []),
            }

            # --- ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ---
            start_time = time.time()
            config = {
                "callbacks": [langfuse_handler], 
                "run_name": f"Batch_Run_{row['id']}"
            }

            # ë­í“¨ì¦ˆ íƒ€ì„ì•„ì›ƒì´ë‚˜ ëª¨ë¸ ì„œë²„ ì¼ì‹œì  ì˜¤ë¥˜ ë“±ìœ¼ë¡œ ë°°ì¹˜ê°€ ë©ˆì¶”ì§€ ì•Šê²Œ ë³´í˜¸
            try:
                final_state = app.invoke(sample_input, config=config)
            except Exception as e:
                print(f"âš ï¸ ì¶”ë¡  ì‹¤íŒ¨ (ID: {row['id']}): {e}")
                # ì‹¤íŒ¨í•œ ë°ì´í„°ë„ ê²°ê³¼ì—ëŠ” ë‚¨ê¹€ (ì¶”í›„ ë¶„ì„ìš©)
                results.append({
                    "id": row['id'],
                    "is_correct": False,
                    "pred_answer": "ERROR",
                    "full_response": str(e)
                })
                continue

            latency = round(time.time() - start_time, 2)

            # ê²°ê³¼ ìˆ˜ì§‘ ë° ì‹¤ì‹œê°„ ì±„ì 
            correct_ans = str(prob_data.get('answer', ''))
            pred_ans = str(final_state.get('final_answer', 'N/A'))
            
            results.append({
                "id": row['id'],
                "question": sample_input["question"],
                "correct_answer": correct_ans,
                "pred_answer": pred_ans,
                "is_correct": correct_ans == pred_ans,
                "full_response": final_state.get('full_response'),
                "latency": latency
            })

            # 4. ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ê´€ë¦¬ (A100 VRAM ë³´í˜¸ ë£¨í‹´)
            # 5ë¬¸ì œë§ˆë‹¤ ìºì‹œë¥¼ ë¹„ì›Œ ë¦¬ë­ì»¤ì™€ ì„œë²„ì˜ VRAM ì¶©ëŒ ë°©ì§€
            if index % 5 == 0:
                gc.collect()
                torch.cuda.empty_cache()

        except Exception as e:
            print(f"ğŸš¨ ì‹¬ê°í•œ ë°ì´í„° ì—ëŸ¬ (Index: {index}): {e}")
            continue

    # 5. ê²°ê³¼ ì €ì¥ ë° í†µê³„
    results_df = pd.DataFrame(results)
    save_path = "result.csv"
    results_df.to_csv(save_path, index=False, encoding='utf-8-sig')

    if not results_df.empty:
        acc = (results_df['is_correct'].sum() / len(results_df)) * 100
        print(f"\nâœ¨ ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ! ìµœì¢… ì •ë‹µë¥ : {acc:.2f}%")
        print(f"ğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")

if __name__ == "__main__":
    main()